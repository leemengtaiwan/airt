# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/serve.ipynb.

# %% auto 0
__all__ = ['device', 'model_id', 'pipe', 'route_info', 'app', 'do_nothing', 'Request', 'txt2img']

# %% ../nbs/serve.ipynb 3
import tempfile
import os
import io
import base64
import PIL
import random
from pprint import pprint

import torch
from diffusers import StableDiffusionPipeline

import pydantic


from datascience_toolkits.fastapi import create_app, serve

# %% ../nbs/serve.ipynb 4
device = torch.device('cuda')

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id, torch_dtype=torch.float16, revision="fp16")

def do_nothing(clip_input, images):
    return images, [0] * len(images)


pipe.safety_checker = do_nothing
pipe = pipe.to(device)

_ = pipe("", num_inference_steps=1)


# %% ../nbs/serve.ipynb 5
class Request(pydantic.BaseModel):
    prompt: str
    steps: int = 1
    guidance_scale: float = 7.5
    negative_prompt: str = None
    batch_size: int = 1
    seed: int = None
    mode: str = "txt2img"
    init_image: str = None
    strength: float = 0.8
        


async def txt2img(req: Request):
    pprint(req)
    tempdir = tempfile.gettempdir()
    local_dir = os.path.join(tempdir, "test.png")
    
    seed = req.seed if req.seed else random.randint(1, 1000000000)
    torch.manual_seed(seed)

    pipe_out = pipe(
        prompt=req.prompt, 
        num_inference_steps=req.steps,
        guidance_scale=req.guidance_scale,
        negative_prompt=req.negative_prompt,
    )
    images = pipe_out.images

    
    b64images = []
    for img in images:
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue())
        b64images.append(img_str.decode())
    return {
        'images': b64images,
        'seed': seed,
    }
    

route_info = [{
    "path": "/",
    "method": "post",
    "endpoint": txt2img
}]

app = create_app(route_info)
serve(app)
